{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098c5083-6bd3-4082-b097-8e7cf666a45a",
   "metadata": {},
   "source": [
    "Collecting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17da7a7-7d27-4ce5-8160-2b1448862859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_capture():\n",
    "    import pyscreenshot as ImageGrab\n",
    "    import time\n",
    "\n",
    "    #images_folder = \"captured_images/0/\"\n",
    "    images_folder = \"new_images/\" # this is for testing\n",
    "    \n",
    "    for i in range(10):\n",
    "        time.sleep(10)\n",
    "        im = ImageGrab.grab(bbox = (150, 200, 1150, 800)) # coordinates capturing image on screen\n",
    "        print(\"saved..\", i)\n",
    "        im.save(images_folder+str(i)+'.png')\n",
    "        print(\"Clear screen and redraw again...\")\n",
    "\n",
    "screen_capture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b353d07-5099-4796-8e73-dffa94ae8584",
   "metadata": {},
   "source": [
    "Create data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ee9df6-ddb3-4179-b735-75b0484cc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # pip install numpy\n",
    "\n",
    "def create_label(image_name):\n",
    "    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n",
    "    if image_name == '0':  \n",
    "        return np.array([1,0,0,0,0,0,0,0,0,0])\n",
    "    elif image_name == '1':\n",
    "        return np.array([0,1,0,0,0,0,0,0,0,0])\n",
    "    elif image_name == '2':\n",
    "        return np.array([0,0,1,0,0,0,0,0,0,0])\n",
    "    elif image_name == '3':\n",
    "        return np.array([0,0,0,1,0,0,0,0,0,0])\n",
    "    elif image_name == '4':\n",
    "        return np.array([0,0,0,0,1,0,0,0,0,0])\n",
    "    elif image_name == '5':\n",
    "        return np.array([0,0,0,0,0,1,0,0,0,0])\n",
    "    elif image_name == '6':\n",
    "        return np.array([0,0,0,0,0,0,1,0,0,0])\n",
    "    elif image_name == '7':\n",
    "        return np.array([0,0,0,0,0,0,0,1,0,0])\n",
    "    elif image_name == '8':\n",
    "        return np.array([0,0,0,0,0,0,0,0,1,0])\n",
    "    elif image_name == '9':\n",
    "        return np.array([0,0,0,0,0,0,0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7250423c-f645-48b1-8b15-bce7ddb7180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install require dependencies\n",
    "import os\n",
    "import cv2 #pip install opencv-python\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    " \n",
    "def create_data():\n",
    "    data = []\n",
    "    for folder in tqdm(os.listdir(\"captured_images\")):\n",
    "        # Iterate through each image file in the current folder\n",
    "        for img in os.listdir(\"captured_images/\"+folder):  # Construct path to the image file\n",
    "            path = os.path.join(\"captured_images\",folder, img)  # Read image in grayscale mode\n",
    "            #use image read from open cv\n",
    "            img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "            try:\n",
    "                #resize image\n",
    "                img_data = cv2.resize(img_data, (28,28))\n",
    "            except cv2.error as e:\n",
    "                continue\n",
    "            data.append([np.array(img_data), create_label(folder)])\n",
    "    shuffle(data)  # Randomly shuffle the data to prevent sequence bias\n",
    "    return data  # Return the shuffled list of image data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc711947-b987-4af6-8dd2-41df6e770871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 144.94it/s]"
     ]
    }
   ],
   "source": [
    "data = create_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e417b8-bce4-47ad-961f-d3aae6378a27",
   "metadata": {},
   "source": [
    "Divide data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58e565-0a36-40b6-acdf-ca480e33b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:800]\n",
    "test = data[800:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1, 28,28, 1)\n",
    "y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1, 28,28, 1)\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4643cb40-4798-49e2-8625-5c0ab09d4056",
   "metadata": {},
   "source": [
    "Build the model\n",
    "\n",
    "Steps of Convolutional neural network:\n",
    "1. Convolution layers\n",
    "2. Normalization\n",
    "3. Pooling\n",
    "4. Fully connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ae811-c0c0-40fc-bd39-e6e35d51f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " \n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91296f-eb5a-48ea-8d4d-4ebfb0ae0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the default TensorFlow graph to clear any residual from previous runs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define the input layer with shape 28x28 pixels and 1 color channel (grayscale)\n",
    "convnet = input_data(shape=[28,28, 1], name='input')\n",
    "# Add a convolutional layer with 32 filters of size 5x5 and ReLU activation\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# Add a max pooling layer with a 5x5 pooling window to reduce spatial dimensions\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "# Add another convolutional layer with 64 filters of size 5x5 and ReLU activation\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "# Add another max pooling layer with a 5x5 pooling window\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "# Add a convolutional layer with 128 filters of size 5x5 and ReLU activation\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "# Add a max pooling layer with a 5x5 pooling window\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "# Add another convolutional layer with 64 filters of size 5x5 and ReLU activation\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "# Add another max pooling layer with a 5x5 pooling window\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "# Add a convolutional layer with 32 filters of size 5x5 and ReLU activation\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# Add a max pooling layer with a 5x5 pooling window\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "# Add a fully connected layer with 1024 neurons and ReLU activation\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "# Apply dropout to prevent overfitting, keeping 50% of units active\n",
    "convnet = dropout(convnet, 0.5)\n",
    "# Add a fully connected layer with 10 neurons (one for each class) and softmax activation\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "# Define the regression layer to set optimizer, learning rate, and loss function\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=0.001, loss='categorical_crossentropy', name='targets')\n",
    "# Initialize the model with verbose output for TensorFlow to display detailed logs\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "\n",
    "# Fit the model on training data and validate it on test data, running for 12 epochs\n",
    "model.fit({'input': X_train}, {'targets': y_train}, n_epoch=12, validation_set=({'input': X_test}, {'targets': y_test}), show_metric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f17c404-4225-4b90-9f8f-7a80be3db00b",
   "metadata": {},
   "source": [
    "Predict and display output using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02620cdd-face-4644-aa0e-7649fb44eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same step as creating data above\n",
    "def create_test_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"new_images\")):\n",
    "        path = os.path.join(\"new_images\", img)\n",
    "        img_num = img.split('.')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        try:\n",
    "            img_data = cv2.resize(img_data, (28,28))\n",
    "        except cv2.error as e:\n",
    "            continue\n",
    "        data.append([np.array(img_data), img_num])\n",
    " \n",
    "    shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece45e1e-b20a-45e1-90f3-85ec5db38efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb021f6-e873-4cc1-857f-f5dec0f01455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Import the Matplotlib library for plotting\n",
    "\n",
    "# Create a figure with a specified size\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# Loop through the first 10 samples in the test data\n",
    "for num, data in enumerate(test_data[:10]):  \n",
    "    img_data = data[0]  # Extract the image data\n",
    "    y = fig.add_subplot(5, 5, num + 1)  # Add a subplot in a 5x5 grid for each image\n",
    "    orig = img_data  # Save the original image for display\n",
    "    data = img_data.reshape(28,28, 1)  # Reshape the image to (28, 28, 1) for model input\n",
    "\n",
    "    # Predict the label using the trained model\n",
    "    model_out = model.predict([data])  \n",
    "    str_label = \"Prediction: \" + str(np.argmax(model_out))  # Get the predicted class label\n",
    "\n",
    "    # Display the image in grayscale\n",
    "    y.imshow(orig, cmap='gray')  \n",
    "    plt.title(str_label)  # Set the title as the prediction\n",
    "    y.axes.get_xaxis().set_visible(False)  # Hide x-axis\n",
    "    y.axes.get_yaxis().set_visible(False)  # Hide y-axis\n",
    "\n",
    "# Show the figure with all predictions\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e0c83-3081-4a56-863d-cf6167e91ad6",
   "metadata": {},
   "source": [
    "Tutorial Reference & Original Source: https://igtechteam.wordpress.com/2023/06/25/handwritten-digit-recognition-using-cnn-deep-learning-project/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
